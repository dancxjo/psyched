[service.llm]
compose = "docker-compose.yml"
setup_scripts = ["setup.sh"]
description = "GPU-enabled Ollama llm model runtime"
