# Chat module configuration (env)
# Replace TOML with environment variables. Values can be overridden per-process as needed.

# Chat behavior
CHAT_SYSTEM_PROMPT=You_are_a_helpful_assistant._Reply_in_one_concise_sentence.
CHAT_CONVERSATION_TOPIC=/conversation
CHAT_VOICE_TOPIC=/voice

# Model and Ollama server
OLLAMA_MODEL=tinyllama
OLLAMA_HOST=http://localhost:11434

# History
CHAT_MAX_HISTORY=20
