[host]
name = "motherbrain"
installers = ["ros2", "docker"]
# Conversant connects to the forebrain LLM since the motherbrain lacks the GPU capacity to host it locally.
modules = [
    "pilot",
    "eye",
    "faces",
    # "voice",
    # "ear",
    # "memory",
    # "nav",
    # "imu",
    # "gps",
    # "foot",
    # "viscera",
    "cockpit",
]

[config.mod.ear.env]
EAR_BACKEND = "service"
EAR_SERVICE_URI = "ws://forebrain.local:5003/asr"

[[config.mod.ear.dependencies]]
service = "forebrain.asr"
port = "ws"
via = "ws://forebrain.local:5003/asr"
bind_env = "EAR_SERVICE_URI"
summary = "Consumes Whisper websocket for speech recognition"

[config.mod.memory.env]
QDRANT_URL = "http://forebrain.local:6333"
NEO4J_URI = "bolt://forebrain.local:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "test"

[[config.mod.memory.dependencies]]
service = "forebrain.vectors"
port = "http"
via = "http://forebrain.local:6333"
bind_env = "QDRANT_URL"
summary = "Stores memory embeddings in the shared Qdrant cluster"

[[config.mod.memory.dependencies]]
service = "forebrain.graphs"
port = "bolt"
via = "bolt://forebrain.local:7687"
bind_env = "NEO4J_URI"
summary = "Persists memory relationships via Neo4j Bolt endpoint"

[config.mod.faces.launch.arguments]
camera_topic = "/camera/color/image_raw"
faces_topic = "/vision/faces"
face_detected_topic = "/vision/face_detected"

[config.mod.faces.env]
FACES_CAMERA_TOPIC = "/camera/color/image_raw"
FACES_FACES_TOPIC = "/vision/faces"
FACES_FACE_DETECTED_TOPIC = "/vision/face_detected"

[config.mod.eye.launch.arguments]
rgb_topic = "/camera/color/image_raw"
depth_topic = "/camera/depth/image_raw"

[config.mod.gps.launch.arguments]
frame_id = "gps_link"

[config.mod.nav.launch.arguments]
kinect_rgb_topic = "/camera/color/image_raw"
kinect_depth_topic = "/camera/depth/image_raw"
camera_frame = "camera_link"

[config.mod.voice.env]
VOICE_BACKEND = "websocket"
VOICE_TTS_URL = "ws://forebrain.local:5002/tts"

[[config.mod.voice.dependencies]]
service = "forebrain.tts"
port = "ws"
via = "ws://forebrain.local:5002/tts"
bind_env = "VOICE_TTS_URL"
summary = "Streams synthesized speech from the forebrain TTS service"

[config.mod.conversant.env]
CONVERSANT_MODE = "balanced"
CONVERSANT_SILENCE_MS = "900"
CONVERSANT_THREAD_TTL_SECONDS = "240"
CONVERSANT_VAD_TOPIC = "/ear/speech_active"
CONVERSANT_SILENCE_TOPIC = "/ear/silence"
CONVERSANT_LOCAL_LLM_URL = "http://localhost:11434/api/generate"
CONVERSANT_LOCAL_LLM_MODEL = "gemma3:latest"

[[config.mod.conversant.dependencies]]
service = "forebrain.llm"
port = "http"
via = "http://localhost:11434/api/generate"
bind_env = "CONVERSANT_LOCAL_LLM_URL"
summary = "Generates conversational responses via the local Ollama runtime"

[config.mod.hypothalamus]
display_name = "Hypothalamus"

[config.mod.hypothalamus.env]
HYPOTHALAMUS_SENSOR_TYPE = "DHT11"
HYPOTHALAMUS_GPIO_PIN = "D23"

[config.mod.pilot.env]
OLLAMA_HOST = "http://localhost:11434"
