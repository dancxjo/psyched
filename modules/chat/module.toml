name = "chat"
description = "Conversational agent with Ollama backend"

[pilot]
display_name = "Chat"
description = "Conversational agent powered by Ollama"
regimes = ["conversation"]

[[pilot.topics]]
name = "/conversation"
type = "psyched_msgs/msg/Message"
access = "rw"
presentation = "chat"
qos = { history = "keep_last", depth = 20, reliability = "reliable", durability = "volatile" }

[[pilot.topics]]
name = "/voice"
type = "std_msgs/msg/String"
access = "wo"
presentation = "text"
qos = { history = "keep_last", depth = 10, reliability = "reliable", durability = "volatile" }

[[actions]]
type = "link_packages"
packages = ["chat", "psyched_msgs"]

[[actions]]
type = "link_packages"
base = "../voice/packages"
packages = ["voice"]

[[actions]]
type = "pip_install"
packages = ["requests", "websockets>=11,<12"]
import_check = ["requests", "websockets"]
break_system = true

[[actions]]
type = "run"
description = "Install Ollama if missing"
script = "scripts/install_ollama.sh"
optional = true

[[actions]]
type = "run"
description = "Enable Ollama service when available"
script = "scripts/enable_ollama_service.sh"
optional = true

[[actions]]
type = "run"
description = "Ensure configured Ollama model is present"
script = "scripts/ensure_ollama_model.sh"
optional = true

[systemd]
description = "Psyched Chat Service"
after = ["network-online.target"]
wants = ["network-online.target"]
restart_sec = 4
launch_command = "${MODULE_DIR}/chat.launch.sh"
shutdown_command = "${MODULE_DIR}/chat.shutdown.sh"
